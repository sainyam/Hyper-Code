{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff977570-0a13-403f-ae2a-43c8c8e66775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backdoor_adjustment_opt(df, Y, y, A, a, Z):\n",
    "    prob = 0  # Initialize the probability to 0\n",
    "    total_len = len(df)  # Total number of observations in the dataframe\n",
    "    total_relevant_Z = 0  # Counter for the total number of observations relevant for the confounders Z\n",
    "    unique_Z_combinations = df[Z].drop_duplicates()  # Get unique combinations of confounder values\n",
    "    \n",
    "    # Iterate over each unique combination of confounder values\n",
    "    for z_values in unique_Z_combinations.itertuples(index=False):\n",
    "        mask_Z = np.ones(len(df), dtype=bool)  # Initialize a mask to select rows corresponding to the current combination of Z values\n",
    "        \n",
    "        # Create the mask for the current Z values\n",
    "        for column, value in zip(Z, z_values):\n",
    "            mask_Z = mask_Z & (df[column] == value)  # Update the mask to select rows where the current confounder matches its value in the current combination\n",
    "        \n",
    "        df_Z = df[mask_Z]  # Apply the mask to filter the dataframe for the current Z values\n",
    "        df_A_a_Z = df_Z[df_Z[A] == a]  # Further filter the dataframe for rows where A equals the intervention value a\n",
    "\n",
    "        # If there are rows matching the current Z values and A=a, calculate the conditional probability of Y=y\n",
    "        if not df_A_a_Z.empty:\n",
    "            p_Y_given_A_Z = (df_A_a_Z[Y] == y).sum() / len(df_A_a_Z)  # Calculate P(Y=y|A=a,Z)\n",
    "            p_Z = len(df_Z) / total_len  # Calculate P(Z), the probability of the current combination of Z values\n",
    "            total_relevant_Z += len(df_Z)  # Update the count of total relevant observations for Z\n",
    "            prob += p_Y_given_A_Z * p_Z  # Accumulate the weighted probability\n",
    "            \n",
    "    # Adjust the final probability based on the proportion of observations that were relevant for the Z values\n",
    "    # This line gurantees sum to 1\n",
    "    if total_relevant_Z > 0:\n",
    "        prob = prob * total_len / total_relevant_Z  # Adjust the probability to account for the distribution of Z values in the data\n",
    "\n",
    "    return prob  # Return the adjusted probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4e323-dca9-49ea-b863-54dd8c7d1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_backdoor_opt_edit2(G, df, k, update_vars, target_column, condition, opt, row_indexes):\n",
    "    ### get the updated dataframe\n",
    "    updated_df = ranking_funcs.get_ranking_query(G, df, len(df), update_vars, target_column, condition, opt)\n",
    "    ### the updated variable\n",
    "    node = list(update_vars.keys())[0]\n",
    "    results = []\n",
    "    ###  theta 2 to theta k list\n",
    "    theta_lst = updated_df[target_column][1:len(df)+1].tolist()\n",
    "    ###  theta 1 to theta k-1 list\n",
    "    prev_theta_lst = updated_df[target_column][0:len(df)].tolist()\n",
    "    ### find the backdoor set path\n",
    "    bd_set = ranking_funcs.find_backdoor_sets_opt(G, target_column, node)[0]\n",
    "    #### get unique values of Y\n",
    "    dom_y = updated_df[target_column].unique()\n",
    "    #### get unique values of updated variable\n",
    "    dom_node = updated_df[node].unique()\n",
    "    ### iteration to get the probaility Sum ùëÉùëü (ùëå = ùë¶|ùëëùëú (ùëã ) = ùë•, ùëç = ùëßùëñ )ùëÉùëü (ùëç =ùëßùëñ ) to calculate ùëÉùëü (ùëå = ùë¶|ùëëùëú (ùëã ) = ùë•)\n",
    "    for d_y in dom_y:\n",
    "        for d_n in dom_node:\n",
    "            adjusted_prob = ranking_funcs.backdoor_adjustment_opt(updated_df, target_column, d_y, node, d_n, list(bd_set))\n",
    "            results.append({\n",
    "                'Y': target_column, \n",
    "                'Y_value': d_y, \n",
    "                'X': node, \n",
    "                'X_value': d_n, \n",
    "                'Z': ', '.join(bd_set), \n",
    "                'prob': adjusted_prob\n",
    "            })\n",
    "    ## get the probability dataframe\n",
    "    prob_df = pd.DataFrame(results)\n",
    "    \n",
    "    prob_groups = []\n",
    "    for row_index in row_indexes:\n",
    "        row = updated_df.loc[row_index]                    \n",
    "        x_value = row[node]\n",
    "        prob_sum = 0\n",
    "        for i in range(k-1):\n",
    "            ### filter the Y values >ùúÉi and corresponding probability\n",
    "            z_relevant_probs = prob_df[(prob_df['Y_value'] > theta_lst[i])]\n",
    "            ### filter the Y values (>ùúÉi and <=ùúÉi ‚àí1) and corresponding probability\n",
    "            z_relevant_probs2 = z_relevant_probs[(z_relevant_probs['Y_value'] <= prev_theta_lst[i])]\n",
    "            ### Prùê∑,ùëìùëà ùëì (ùúÉi) - Prùê∑,ùëìùëà (ùëì (ùúÉi) ‚àß ùëì (ùúÉi ‚àí1)) (sum through the iteration)\n",
    "            ### Sum ùëÉùëü (ùëå = ùë¶ùëó |ùëëùëú (ùëã ) = ùë•) with ùë¶ùëó ‚â• ùúÉi - ùëÉùëü (ùëå = ùë¶ùëó |ùëëùëú (ùëã ) = ùë•) with ùë¶ùëó ‚â• ùúÉi and yj<=ùúÉi-1 (is same to the above)\n",
    "            prob_sum += z_relevant_probs[(z_relevant_probs['X_value'] == x_value)]['prob'].sum()-z_relevant_probs2[(z_relevant_probs2['X_value'] == x_value)]['prob'].sum()\n",
    "        prob_groups.append(prob_sum)\n",
    "        ### get the product of probability of each tupple\n",
    "    return m.prod(prob_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fc16a-e33d-4a3a-a7e2-328755cf70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_backdoor_opt_pred(G, df, k, update_vars, target_column, condition, opt):\n",
    "    \"\"\"\n",
    "    G: causal graph\n",
    "    df:dataframe\n",
    "    k: the top k\n",
    "    update_vars: the variable used for update\n",
    "    target_column: the column the ranking with\n",
    "    condition: the condition for updating\n",
    "    opt: must be one of 'fix','add','subs','multiply_by'or 'divided_by'\n",
    "    row_indexes: the tuples\n",
    "    \"\"\"\n",
    "    ### get the updated dataframe\n",
    "    updated_df = ranking_funcs.get_ranking_query(G, df, len(df), update_vars, target_column, condition, opt)\n",
    "    ### the updated variable\n",
    "    node = list(update_vars.keys())[0]\n",
    "    results = []\n",
    "    ### theta 2 to theta n\n",
    "    theta_lst = updated_df[target_column][1:len(df)+1].tolist()\n",
    "    ###  theta 1 to theta n-1 list\n",
    "    prev_theta_lst = updated_df[target_column][0:len(df)].tolist()\n",
    "    ### find the backdoor set path\n",
    "    bd_set = ranking_funcs.find_backdoor_sets_opt(G, target_column, node)[0]\n",
    "    ### get all the ranking tupple combination, n choose k\n",
    "    tupple_combs = list(combinations(df.index, k))\n",
    "    #### get unique values of Y\n",
    "    dom_y = updated_df[target_column].unique()\n",
    "    #### get unique values of updated variable\n",
    "    dom_node = updated_df[node].unique()\n",
    "    ### iteration to get the probaility Sum ùëÉùëü (ùëå = ùë¶|ùëëùëú (ùëã ) = ùë•, ùëç = ùëßùëñ )ùëÉùëü (ùëç =ùëßùëñ ) to calculate ùëÉùëü (ùëå = ùë¶|ùëëùëú (ùëã ) = ùë•)\n",
    "    for d_y in dom_y:\n",
    "        for d_n in dom_node:\n",
    "            adjusted_prob = ranking_funcs.backdoor_adjustment_opt(updated_df, target_column, d_y, node, d_n, list(bd_set))\n",
    "            results.append({\n",
    "                'Y': target_column, \n",
    "                'Y_value': d_y, \n",
    "                'X': node, \n",
    "                'X_value': d_n, \n",
    "                'Z': ', '.join(bd_set), \n",
    "                'prob': adjusted_prob\n",
    "            })\n",
    "    ## get the probability dataframe\n",
    "    prob_df = pd.DataFrame(results)\n",
    "    prob_groups = []\n",
    "    ### i the ranking combos\n",
    "    for row_indexes in tupple_combs:\n",
    "        for i in range(len(df)-1):\n",
    "            ### filter the Y values >ùúÉi and corresponding probability\n",
    "            z_relevant_probs = prob_df[(prob_df['Y_value'] > theta_lst[i])]\n",
    "            ### filter the Y values (>ùúÉi and <=ùúÉi ‚àí1) and corresponding probability\n",
    "            z_relevant_probs2 = z_relevant_probs[(z_relevant_probs['Y_value'] <= prev_theta_lst[i])]\n",
    "            pro_prod = []\n",
    "            prob_sum = 1\n",
    "            for row_index in row_indexes:\n",
    "                row = updated_df.loc[row_index]                    \n",
    "                x_value = row[node]\n",
    "                ### product Prùê∑,ùëìùëà ùëì (ùúÉi) - Prùê∑,ùëìùëà (ùëì (ùúÉi) ‚àß ùëì (ùúÉi ‚àí1)) for each tupple\n",
    "                prob_sum *= z_relevant_probs[(z_relevant_probs['X_value'] == x_value)]['prob'].sum()-z_relevant_probs2[(z_relevant_probs2['X_value'] == x_value)]['prob'].sum()\n",
    "            #get the product Prùê∑,ùëìùëà ùëì (ùúÉi) - Prùê∑,ùëìùëà (ùëì (ùúÉi) ‚àß ùëì (ùúÉi ‚àí1)) for tuples in a tuple group\n",
    "            pro_prod.append(prob_sum)\n",
    "        ### get the sum of it by iterating all the thetas\n",
    "        prob_groups.append(sum(pro_prod))\n",
    "    ranking_prob_df = {'ranking_combos':tupple_combs,'prob_in_top_k':prob_groups}.sort_values(by='prob_in_top_k',ascending=False)\n",
    "    ### get the highest ranking_combo\n",
    "    return ranking_prob_df.head(1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "daf7f91c-0bef-4a7d-abf0-c25804388f02",
   "metadata": {},
   "source": [
    "Algorithm: get_prob_backdoor_opt_pred\n",
    "Input: \n",
    "    G (causal graph), \n",
    "    df (dataframe), \n",
    "    k (top k combinations), \n",
    "    update_vars (variables for update), \n",
    "    target_column (ranking column), \n",
    "    condition (condition for update), \n",
    "    opt (operation type), \n",
    "    row_indexes (tuples of indexes for ranking)\n",
    "\n",
    "1: updated_df ‚Üê sort and update dataframe using G, df, update_vars, target_column, condition, opt\n",
    "2: node ‚Üê first key from update_vars\n",
    "3: results ‚Üê empty list\n",
    "4: theta_lst ‚Üê values from target_column in updated_df from second to last\n",
    "5: prev_theta_lst ‚Üê values from target_column in updated_df from first to second-to-last\n",
    "6: bd_set ‚Üê find the first backdoor set for target_column against node in G\n",
    "7: tuple_combs ‚Üê list of combinations from df.index, choose k\n",
    "8: dom_y ‚Üê unique values of target_column in updated_df\n",
    "9: dom_node ‚Üê unique values of node in updated_df\n",
    "10: for each d_y in dom_y do\n",
    "11:     for each d_n in dom_node do\n",
    "12:         adjusted_prob ‚Üê calculate backdoor adjustment for d_y, with node = d_n using bd_set\n",
    "13:         append {Y: target_column, Y_value: d_y, X: node, X_value: d_n, Z: bd_set, prob: adjusted_prob} to results\n",
    "14:     end for\n",
    "15: end for\n",
    "16: prob_df ‚Üê create dataframe from results\n",
    "17: prob_groups ‚Üê empty list\n",
    "18: for each tuple_comb in tuple_combs do\n",
    "19:     pro_prod ‚Üê empty list\n",
    "20:     for i from 0 to length of updated_df - 2 do\n",
    "21:         z_relevant_probs ‚Üê filter prob_df where Y_value > theta_lst[i]\n",
    "22:         z_relevant_probs2 ‚Üê filter z_relevant_probs where Y_value ‚â§ prev_theta_lst[i]\n",
    "23:         prob_sum ‚Üê initialize to 1 for each iteration\n",
    "24:         for each row_index in tuple_comb do\n",
    "25:             row ‚Üê updated_df at row_index\n",
    "26:             x_value ‚Üê value of node in row\n",
    "27:             prob_sum *= sum of probs in z_relevant_probs for x_value - sum of probs in z_relevant_probs2 for x_value\n",
    "28:         end for\n",
    "29:         append prob_sum to pro_prod\n",
    "30:     end for\n",
    "31:     append sum of pro_prod to prob_groups\n",
    "32: end for\n",
    "33: ranking_prob_df ‚Üê create dataframe from {'ranking_combos': tuple_combs, 'prob_in_top_k': prob_groups} and sort by 'prob_in_top_k' in descending order\n",
    "34: return the highest ranking_combo from ranking_prob_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fdaead-dd7e-4e29-a568-012fe1d2a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_backdoor_opt(G, df, k, update_vars, target_column, condition, opt):\n",
    "    ### get the updated dataframe\n",
    "    updated_df = ranking_funcs.get_ranking_query(G, df, len(df), update_vars, target_column, condition, opt)\n",
    "    ### the updated variable\n",
    "    node = list(update_vars.keys())[0]\n",
    "    results = []\n",
    "    ### find the one of the backdoor set of updated variable\n",
    "    bd_set = ranking_funcs.find_backdoor_sets_opt(G, target_column, node)[0]\n",
    "    dom_y = updated_df[target_column].unique()\n",
    "    dom_node = updated_df[node].unique()\n",
    "    for d_y in dom_y:\n",
    "        for d_n in dom_node:\n",
    "            adjusted_prob = ranking_funcs.backdoor_adjustment_opt(updated_df, target_column, d_y, node, d_n, list(bd_set))\n",
    "            results.append({\n",
    "                'Y': target_column, \n",
    "                'Y_value': d_y, \n",
    "                'X': node, \n",
    "                'X_value': d_n, \n",
    "                'Z': ', '.join(bd_set), \n",
    "                'prob': adjusted_prob\n",
    "            })\n",
    "    ## get the probability dataframe\n",
    "    prob_df = pd.DataFrame(results)\n",
    "    group_df['expected_value']=group_df['prob']*group_df[target_column]\n",
    "    prob_df = group_df.groupby([node]).agg({'expected_value': 'sum'}).reset_index()\n",
    "    \n",
    "    expected_values = []\n",
    "    for row_index, row in updated_df.iterrows():                  \n",
    "        match_conditions = row[node]\n",
    "        matched_row = prob_df[prob_df[node] == match_conditions]\n",
    "        if not matched_row.empty:\n",
    "            expected_value = matched_row['expected_value'].values[0]\n",
    "        else:\n",
    "            expected_value=0\n",
    "        expected_values.append(expected_value)\n",
    "        \n",
    "    result_df = pd.DataFrame({'row_index': updated_df.index, 'expected_value': expected_values})\n",
    "    return result_df.sort_values(by='expected_value', ascending=False).head(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a5061-d705-4315-9476-7d489f414910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_backdoor_opt2(G, df, k, update_vars, target_column, condition, opt):\n",
    "    \"\"\"\n",
    "    Use P(Y|do(X),Z) to estimate\n",
    "    \"\"\"\n",
    "    updated_df = get_ranking_query(G, df, len(df), update_vars, target_column, condition, opt)\n",
    "    node = list(update_vars.keys())[0]\n",
    "    results = []\n",
    "    bd_set = ranking_funcs.find_backdoor_sets_opt(G, target_column, node)[0]\n",
    "    dom_y = updated_df[target_column].unique()\n",
    "    dom_node = updated_df[node].unique()\n",
    "    for d_y in dom_y:\n",
    "        for d_n in dom_node:\n",
    "            result_df = backdoor_adjustment_opt2(updated_df, target_column, d_y, node, d_n, list(bd_set))\n",
    "            if not result_df.empty:\n",
    "                results.append(result_df)\n",
    "\n",
    "    merged_df = pd.concat(results, ignore_index=True)\n",
    "    flat_bd_sets = [col for subset in bd_sets for col in subset]+[node]\n",
    "    grouped_df = merged_df.groupby(flat_bd_sets).agg({'expected_value': 'sum'}).reset_index()\n",
    "\n",
    "    expected_values = []\n",
    "    for row_index, row in updated_df.iterrows():\n",
    "        match_conditions = {col: row[col] for col in flat_bd_sets}\n",
    "        matched_row = grouped_df[(grouped_df[list(match_conditions)] == pd.Series(match_conditions)).all(axis=1)]\n",
    "        if not matched_row.empty:\n",
    "            expected_value = matched_row['expected_value'].values[0]\n",
    "        expected_values.append(expected_value)\n",
    "\n",
    "    result_df = pd.DataFrame({'row_index': updated_df.index, 'expected_value': expected_values})\n",
    "    return result_df.sort_values(by='expected_value', ascending=False).head(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c8d88-6393-476e-96f7-83628e68eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_backdoor_opt2(G, df, k, update_vars, target_column, condition, opt, row_indexes, theta):\n",
    "    \"\"\"\n",
    "    Use P(Y|do(X),Z) to estimate\n",
    "    \"\"\"\n",
    "    updated_df = get_ranking_query(G, df, len(df), update_vars, target_column, condition, opt)\n",
    "    node = list(update_vars.keys())[0]\n",
    "    results = []\n",
    "    bd_set = ranking_funcs.find_backdoor_sets_opt(G, target_column, node)[0]\n",
    "    dom_y = updated_df[target_column].unique()\n",
    "    dom_node = updated_df[node].unique()\n",
    "    for d_y in dom_y:\n",
    "        for d_n in dom_node:\n",
    "            result_df = backdoor_adjustment_opt2(updated_df, target_column, d_y, node, d_n, list(bd_set))\n",
    "            if not result_df.empty:\n",
    "                results.append(result_df)\n",
    "    merged_df = pd.concat(results, ignore_index=True)\n",
    "    flat_bd_sets = [col for subset in bd_sets for col in subset]+[node]\n",
    "    filtered_merged_df=merged_df[merged_df['Y_value']>=theta]\n",
    "    prob_df=filtered_merged_df.groupby(flat_bd_sets).agg({'probs': 'sum'}).reset_index()\n",
    "    \n",
    "    total_probs = []\n",
    "    for row_index in row_indexes:\n",
    "        row = updated_df.loc[row_index]                    \n",
    "        match_conditions = {col: row[col] for col in flat_bd_sets}\n",
    "        matched_row = prob_df[(prob_df[list(match_conditions)] == pd.Series(match_conditions)).all(axis=1)]\n",
    "        if not matched_row.empty:\n",
    "            total_prob = matched_row['probs'].values[0]\n",
    "        else:\n",
    "            total_prob=0\n",
    "        total_probs.append(total_prob)\n",
    "        \n",
    "    result_df = pd.DataFrame({'row_index': row_indexes, 'total_probs': total_probs})\n",
    "    return result_df['total_probs'].prod()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
